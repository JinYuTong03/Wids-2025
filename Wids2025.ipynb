{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy/hB1rYrptL6S1HXEUuPf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinYuTong03/Wids-2025/blob/main/Wids2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhPesCjr-fJY"
      },
      "outputs": [],
      "source": [
        "# First mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save uploaded files to Google Drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Create directory to store data files\n",
        "!mkdir -p /content/drive/MyDrive/wids_datathon\n",
        "\n",
        "# Copy uploaded files to Google Drive\n",
        "input_files = {\n",
        "    'train_cat': 'TRAIN_CATEGORICAL_METADATA_new.xlsx',\n",
        "    'train_quant': 'TRAIN_QUANTITATIVE_METADATA_new.xlsx',\n",
        "    'solutions': 'TRAINING_SOLUTIONS.xlsx',\n",
        "    'test_cat': 'TEST_CATEGORICAL.xlsx',\n",
        "    'test_quant': 'TEST_QUANTITATIVE_METADATA.xlsx',\n",
        "    'train_connectome': 'TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv',\n",
        "    'test_connectome': 'TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv'\n",
        "}\n",
        "\n",
        "for key, filename in input_files.items():\n",
        "    if os.path.exists(filename):\n",
        "        shutil.copy(filename, f'/content/drive/MyDrive/wids_datathon/{filename}')\n",
        "        print(f\"File {filename} has been saved to Google Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# WiDS Datathon 2025 - ADHD and Gender Prediction with Multimodal Data\n",
        "# Final Version (Simplified Connectome + No Extra Interaction Features + Hyperparameter Tuning + Single Best Model)\n",
        "# ====================================\n",
        "\n",
        "!pip install neuroCombat\n",
        "!pip install neuroHarmonize\n",
        "!pip install optuna\n",
        "from neuroHarmonize import harmonizationLearn\n",
        "\n",
        "# === 1. ML Setup and Library Imports ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Optional\n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "from time import time\n",
        "import warnings\n",
        "import optuna\n",
        "\n",
        "# Preprocessing & Feature Engineering\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # Keep OneHotEncoder in case of future categorical features\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from scipy import stats\n",
        "import networkx as nx\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# Modeling & Evaluation\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, auc, confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.base import clone\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# ====================================\n",
        "# 2. Data Loading\n",
        "# ====================================\n",
        "def load_data(categorical_path, quantitative_path, solutions_path=None,\n",
        "              test_categorical_path=None, test_quantitative_path=None,\n",
        "              train_connectome_path=None, test_connectome_path=None):\n",
        "    \"\"\"Load training and test data\"\"\"\n",
        "    # [Function body same as before]\n",
        "    print(\"Loading data files...\")\n",
        "    train_categorical, train_quantitative, train_connectome, solutions = None, None, None, None\n",
        "    test_categorical, test_quantitative, test_connectome = None, None, None\n",
        "    try:\n",
        "        if categorical_path.endswith('.xlsx'): train_categorical = pd.read_excel(categorical_path)\n",
        "        else: train_categorical = pd.read_csv(categorical_path)\n",
        "        print(f\"Training categorical data shape: {train_categorical.shape}\")\n",
        "    except Exception as e: print(f\"Error loading {categorical_path}: {e}\")\n",
        "    try:\n",
        "        if quantitative_path.endswith('.xlsx'): train_quantitative = pd.read_excel(quantitative_path)\n",
        "        else: train_quantitative = pd.read_csv(quantitative_path)\n",
        "        print(f\"Training quantitative data shape: {train_quantitative.shape}\")\n",
        "    except Exception as e: print(f\"Error loading {quantitative_path}: {e}\")\n",
        "    if train_connectome_path and os.path.exists(train_connectome_path):\n",
        "        try: train_connectome = pd.read_csv(train_connectome_path); print(f\"Training connectome shape: {train_connectome.shape}\")\n",
        "        except Exception as e: print(f\"Error loading {train_connectome_path}: {e}\")\n",
        "    else: print(f\"Warning: Training connectome file not found: {train_connectome_path}\")\n",
        "    if solutions_path and os.path.exists(solutions_path):\n",
        "        try:\n",
        "            if solutions_path.endswith('.xlsx'): solutions = pd.read_excel(solutions_path)\n",
        "            else: solutions = pd.read_csv(solutions_path)\n",
        "            print(f\"Target variable data shape: {solutions.shape}\")\n",
        "        except Exception as e: print(f\"Error loading {solutions_path}: {e}\")\n",
        "    else: print(f\"Warning: Training solutions file not found: {solutions_path}\")\n",
        "    if test_categorical_path and test_quantitative_path and os.path.exists(test_categorical_path) and os.path.exists(test_quantitative_path):\n",
        "        try:\n",
        "            if test_categorical_path.endswith('.xlsx'): test_categorical = pd.read_excel(test_categorical_path)\n",
        "            else: test_categorical = pd.read_csv(test_categorical_path)\n",
        "            print(f\"Test categorical data shape: {test_categorical.shape}\")\n",
        "        except Exception as e: print(f\"Error loading {test_categorical_path}: {e}\")\n",
        "        try:\n",
        "            if test_quantitative_path.endswith('.xlsx'): test_quantitative = pd.read_excel(test_quantitative_path)\n",
        "            else: test_quantitative = pd.read_csv(test_quantitative_path)\n",
        "            print(f\"Test quantitative data shape: {test_quantitative.shape}\")\n",
        "        except Exception as e: print(f\"Error loading {test_quantitative_path}: {e}\")\n",
        "        if test_connectome_path and os.path.exists(test_connectome_path):\n",
        "            try: test_connectome = pd.read_csv(test_connectome_path); print(f\"Test connectome shape: {test_connectome.shape}\")\n",
        "            except Exception as e: print(f\"Error loading {test_connectome_path}: {e}\")\n",
        "        else: print(f\"Warning: Test connectome file not found: {test_connectome_path}\")\n",
        "    else: print(\"Warning: Test file paths are incomplete or files do not exist.\")\n",
        "    return (train_categorical, train_quantitative, train_connectome, solutions, test_categorical, test_quantitative, test_connectome)\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 3. Data Preprocessing and Merging\n",
        "# ====================================\n",
        "def preprocess_and_merge_data(train_categorical, train_quantitative, solutions=None,\n",
        "                              test_categorical=None, test_quantitative=None):\n",
        "    \"\"\"Preprocess and merge data from different sources\"\"\"\n",
        "    # [Function body same as before]\n",
        "    print(\"\\nPreprocessing and merging data...\")\n",
        "    train_merged, test_merged = None, None\n",
        "    if train_categorical is None or train_quantitative is None: print(\"Error: Training data is missing\"); return None, None\n",
        "    try:\n",
        "        train_cat = train_categorical.copy(); train_quant = train_quantitative.copy()\n",
        "        common_cols = list(set(train_cat.columns) & set(train_quant.columns) - {'participant_id'})\n",
        "        if common_cols: print(f\"Warning: Common columns: {common_cols}\")\n",
        "        train_merged = train_cat.merge(train_quant, on='participant_id', how='inner', suffixes=('_cat', '_quant'))\n",
        "        print(f\"Merged training data shape: {train_merged.shape}\")\n",
        "        if solutions is not None: train_merged = train_merged.merge(solutions, on='participant_id', how='inner'); print(f\"Training data with targets shape: {train_merged.shape}\")\n",
        "        else: print(\"Warning: No target variables provided\")\n",
        "    except Exception as e: print(f\"Error merging training data: {e}\"); return None, None\n",
        "    if test_categorical is not None and test_quantitative is not None:\n",
        "        try: test_cat = test_categorical.copy(); test_quant = test_quantitative.copy(); test_merged = test_cat.merge(test_quant, on='participant_id', how='inner', suffixes=('_cat', '_quant')); print(f\"Merged test data shape: {test_merged.shape}\")\n",
        "        except Exception as e: print(f\"Error merging test data: {e}\")\n",
        "    return train_merged, test_merged\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 2.5. Improved Neuroimaging Data Processing\n",
        "# ====================================\n",
        "\n",
        "# --- Necessary Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy import stats\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import math # For sqrt and isclose\n",
        "from time import time\n",
        "\n",
        "# --- ConnectomeProcessor Class Definition (including all discussed metrics) ---\n",
        "class ConnectomeProcessor:\n",
        "    \"\"\"Processes functional connectome matrices to extract statistics and richer graph theory metrics\"\"\"\n",
        "\n",
        "    def __init__(self, n_jobs=-1):\n",
        "        self.n_jobs = n_jobs\n",
        "        self.selector = None\n",
        "        self.feature_columns = None\n",
        "        # --- Default values including all metrics ---\n",
        "        self.network_metric_defaults = {\n",
        "            'avg_degree': 0, 'max_degree': 0, 'min_degree': 0,\n",
        "            'degree_variance': 0,\n",
        "            'avg_betweenness': 0,      # Re-added\n",
        "            'avg_closeness': 0,        # Re-added\n",
        "            'pos_density': 0, 'neg_density': 0,\n",
        "            'avg_clustering': 0,       # Re-added\n",
        "            'global_efficiency': 0,    # Re-added\n",
        "            'components_0.3': 0, 'components_0.5': 0,\n",
        "            'largest_cc_0.3': 0, 'largest_cc_0.5': 0\n",
        "        }\n",
        "\n",
        "    def extract_participant_features(self, participant_id, corr_values):\n",
        "        \"\"\"\n",
        "        Extract features (including basic statistics and all graph metrics).\n",
        "        \"\"\"\n",
        "        metrics = {'participant_id': participant_id}\n",
        "        try:\n",
        "            corr_values = np.array(corr_values, dtype=float).flatten()\n",
        "        except ValueError:\n",
        "            print(f\"Error: P:{participant_id}'s corr_values contain invalid values. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        # --- 1. Basic Connectivity Statistics [Logic unchanged] ---\n",
        "        if len(corr_values) > 0 and not np.all(np.isnan(corr_values)):\n",
        "            metrics['mean_connectivity'] = np.nanmean(corr_values)\n",
        "            metrics['std_connectivity'] = np.nanstd(corr_values)\n",
        "            valid_corr = corr_values[~np.isnan(corr_values)]\n",
        "            if len(valid_corr) > 0:\n",
        "                metrics['positive_connectivity_ratio'] = np.mean(valid_corr > 0)\n",
        "                metrics['strong_pos_conn_ratio'] = np.mean(valid_corr > 0.5)\n",
        "                metrics['strong_neg_conn_ratio'] = np.mean(valid_corr < -0.5)\n",
        "                if len(valid_corr) > 2:\n",
        "                    metrics['skewness'] = stats.skew(valid_corr)\n",
        "                    metrics['kurtosis'] = stats.kurtosis(valid_corr)\n",
        "                else: metrics['skewness'], metrics['kurtosis'] = 0, 0\n",
        "            else: metrics.update({'positive_connectivity_ratio': 0, 'strong_pos_conn_ratio': 0, 'strong_neg_conn_ratio': 0, 'skewness': 0, 'kurtosis': 0})\n",
        "        else:\n",
        "            metrics.update({'mean_connectivity': 0, 'std_connectivity': 0, 'positive_connectivity_ratio': 0, 'strong_pos_conn_ratio': 0, 'strong_neg_conn_ratio': 0, 'skewness': 0, 'kurtosis': 0})\n",
        "            metrics.update(self.network_metric_defaults); return metrics\n",
        "\n",
        "        # --- 2. Network Feature Extraction ---\n",
        "        n_regions = 0\n",
        "        matrix_valid = False\n",
        "        # [Matrix dimension calculation and validation logic unchanged]\n",
        "        M = len(corr_values)\n",
        "        if M > 0:\n",
        "            delta = 1 + 8 * M\n",
        "            if delta >= 0:\n",
        "                sqrt_delta = math.sqrt(delta)\n",
        "                N_float = (1 + sqrt_delta) / 2\n",
        "                if math.isclose(N_float, round(N_float)):\n",
        "                    n_regions_calc = int(round(N_float))\n",
        "                    if n_regions_calc > 0 and n_regions_calc * (n_regions_calc - 1) // 2 == M:\n",
        "                        n_regions = n_regions_calc; matrix_valid = True\n",
        "        # Initialize all network metrics to default values\n",
        "        metrics.update(self.network_metric_defaults)\n",
        "        metrics['components_0.3'] = n_regions if matrix_valid else 0\n",
        "        metrics['components_0.5'] = n_regions if matrix_valid else 0\n",
        "        metrics['largest_cc_0.3'] = 0; metrics['largest_cc_0.5'] = 0\n",
        "        if not matrix_valid: return metrics\n",
        "\n",
        "        # --- If the matrix is valid, try to calculate all metrics ---\n",
        "        try:\n",
        "            matrix = np.zeros((n_regions, n_regions))\n",
        "            triu_indices = np.triu_indices(n_regions, k=1)\n",
        "            if len(triu_indices[0]) == M:\n",
        "                corr_values_filled = np.nan_to_num(corr_values, nan=0.0)\n",
        "                matrix[triu_indices] = corr_values_filled\n",
        "            else: print(f\"Error: P:{participant_id} internal mismatch of index/value counts\"); return metrics\n",
        "            matrix = matrix + matrix.T; matrix_abs = np.abs(matrix)\n",
        "\n",
        "            G_full = nx.from_numpy_array(matrix_abs)\n",
        "            G_unweighted = nx.from_numpy_array((matrix_abs > 1e-6).astype(int))\n",
        "\n",
        "            # --- Extract basic and new network metrics ---\n",
        "            if G_full.number_of_nodes() > 0:\n",
        "                degrees = [d for _, d in G_full.degree(weight='weight')]\n",
        "                if degrees:\n",
        "                    metrics['avg_degree'] = np.mean(degrees)\n",
        "                    metrics['max_degree'] = np.max(degrees)\n",
        "                    metrics['min_degree'] = np.min(degrees)\n",
        "                    metrics['degree_variance'] = np.var(degrees)\n",
        "\n",
        "                # ===> Re-adding complex metric calculations <===\n",
        "                try:\n",
        "                    betweenness = nx.betweenness_centrality(G_unweighted, normalized=True)\n",
        "                    metrics['avg_betweenness'] = np.mean(list(betweenness.values()))\n",
        "                except Exception as e_bw: print(f\"  P:{participant_id} Betweenness failed: {e_bw}\")\n",
        "\n",
        "                try:\n",
        "                    closeness = nx.closeness_centrality(G_unweighted)\n",
        "                    metrics['avg_closeness'] = np.mean(list(closeness.values()))\n",
        "                except Exception as e_cl: print(f\"  P:{participant_id} Closeness failed: {e_cl}\")\n",
        "\n",
        "                try:\n",
        "                    metrics['avg_clustering'] = nx.average_clustering(G_full, weight='weight')\n",
        "                except Exception as e_cc: print(f\"  P:{participant_id} Clustering failed: {e_cc}\")\n",
        "\n",
        "                try:\n",
        "                    metrics['global_efficiency'] = nx.global_efficiency(G_unweighted)\n",
        "                except Exception as e_ge: print(f\"  P:{participant_id} Efficiency failed: {e_ge}\")\n",
        "                # ===> End of complex metric calculations <===\n",
        "\n",
        "            # --- Density Calculation ---\n",
        "            matrix_filled = np.nan_to_num(matrix, nan=0.0)\n",
        "            G_pos = nx.from_numpy_array(np.where(matrix_filled > 0, matrix_filled, 0))\n",
        "            G_neg = nx.from_numpy_array(np.where(matrix_filled < 0, -matrix_filled, 0))\n",
        "            metrics['pos_density'] = nx.density(G_pos); metrics['neg_density'] = nx.density(G_neg)\n",
        "\n",
        "            # --- Threshold Analysis (including largest connected component) ---\n",
        "            for threshold in [0.3, 0.5]:\n",
        "                G_thresh = nx.Graph(); G_thresh.add_nodes_from(range(n_regions))\n",
        "                for u, v, d in G_full.edges(data=True):\n",
        "                    if d.get('weight', 0) > threshold: G_thresh.add_edge(u, v, weight=d['weight'])\n",
        "                metrics[f'components_{threshold}'] = nx.number_connected_components(G_thresh)\n",
        "                try:\n",
        "                    components = list(nx.connected_components(G_thresh))\n",
        "                    if components: largest_cc = max(components, key=len); metrics[f'largest_cc_{threshold}'] = len(largest_cc) / n_regions\n",
        "                except Exception as e_lcc: print(f\"  P:{participant_id} LargestCC failed (thr={threshold}): {e_lcc}\")\n",
        "\n",
        "        except Exception as e: print(f\"Error calculating network metrics for P:{participant_id}: {e}\")\n",
        "        return metrics\n",
        "\n",
        "    # --- Methods _get_corr_cols, fit_transform, transform remain unchanged ---\n",
        "    # [Code same as the previous version]\n",
        "    def _get_corr_cols(self, df):\n",
        "        corr_cols = [col for col in df.columns if 'throw_' in col]\n",
        "        if not corr_cols:\n",
        "            numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "            if len(numeric_cols) > 0.8 * len(df.columns):\n",
        "                potential_cols = numeric_cols.drop('participant_id', errors='ignore').tolist()\n",
        "                if potential_cols: print(\"Warning: 'throw_' columns not found...\"); return potential_cols\n",
        "                else: raise ValueError(\"Connectome data columns not found (auto-detection failed).\")\n",
        "            else: raise ValueError(\"Connectome data columns not found ('throw_' or majority numeric columns).\")\n",
        "        return corr_cols\n",
        "\n",
        "    def fit_transform(self, connectome_df):\n",
        "        print(\"  Executing connectome fit_transform...\")\n",
        "        if 'participant_id' not in connectome_df.columns: raise ValueError(\"'participant_id' column is missing\")\n",
        "        corr_cols = self._get_corr_cols(connectome_df)\n",
        "        participant_ids = connectome_df['participant_id'].tolist()\n",
        "        corr_values_list = connectome_df[corr_cols].values.tolist()\n",
        "        features = Parallel(n_jobs=self.n_jobs)(delayed(self.extract_participant_features)(pid, vals) for pid, vals in zip(participant_ids, corr_values_list))\n",
        "        valid_features = [f for f in features if f is not None]\n",
        "        if not valid_features: print(\"Warning: No valid features\"); return pd.DataFrame(columns=['participant_id'])\n",
        "        features_df = pd.DataFrame(valid_features).set_index('participant_id')\n",
        "        self.feature_columns = features_df.columns.tolist()\n",
        "        if not self.feature_columns: print(\"Warning: No feature columns extracted\"); return features_df.reset_index()[['participant_id']]\n",
        "        self.medians_ = features_df.median()\n",
        "        feature_matrix = features_df.fillna(self.medians_)\n",
        "        self.selector = VarianceThreshold(threshold=0.01)\n",
        "        try:\n",
        "            self.selector.fit(feature_matrix)\n",
        "            selected_features_mask = self.selector.get_support()\n",
        "            selected_features = feature_matrix.columns[selected_features_mask]\n",
        "            processed_matrix = self.selector.transform(feature_matrix)\n",
        "            print(f\"  Number of features remaining after VarianceThreshold: {len(selected_features)}\")\n",
        "            if len(selected_features) == 0: print(\"Warning: No features remaining\"); selected_features = feature_matrix.columns; processed_matrix = feature_matrix.values; self.selector = None\n",
        "        except ValueError as ve: print(f\"Warning: VarianceThreshold failed: {ve}\"); selected_features = feature_matrix.columns; processed_matrix = feature_matrix.values; self.selector = None\n",
        "        processed_df = pd.DataFrame(processed_matrix, columns=selected_features, index=features_df.index).reset_index()\n",
        "        self.final_feature_columns_ = selected_features.tolist()\n",
        "        return processed_df\n",
        "\n",
        "    def transform(self, connectome_df):\n",
        "        print(\"  Executing connectome transform...\")\n",
        "        if self.feature_columns is None: raise ValueError(\"Processor has not been fitted\")\n",
        "        if 'participant_id' not in connectome_df.columns: raise ValueError(\"'participant_id' column is missing\")\n",
        "        corr_cols = self._get_corr_cols(connectome_df)\n",
        "        participant_ids = connectome_df['participant_id'].tolist()\n",
        "        corr_values_list = connectome_df[corr_cols].values.tolist()\n",
        "        features = Parallel(n_jobs=self.n_jobs)(delayed(self.extract_participant_features)(pid, vals) for pid, vals in zip(participant_ids, corr_values_list))\n",
        "        valid_features = [f for f in features if f is not None]\n",
        "        if not valid_features: print(\"Warning: No valid features in test data\"); final_cols = self.final_feature_columns_ if hasattr(self, 'final_feature_columns_') else []; return pd.DataFrame(columns=['participant_id'] + final_cols)\n",
        "        features_df = pd.DataFrame(valid_features).set_index('participant_id')\n",
        "        if not hasattr(self, 'medians_'): print(\"Warning: Training medians not stored\"); self.medians_ = 0\n",
        "        feature_matrix = features_df.reindex(columns=self.feature_columns).fillna(self.medians_)\n",
        "        if self.selector is not None and hasattr(self, 'final_feature_columns_'):\n",
        "            try: processed_matrix = self.selector.transform(feature_matrix); selected_features = self.final_feature_columns_\n",
        "            except ValueError as ve: print(f\"Warning: VT transform failed: {ve}.\"); processed_matrix = feature_matrix.values; selected_features = self.feature_columns\n",
        "            except Exception as e: print(f\"Error in VT transform: {e}\"); raise\n",
        "        else: processed_matrix = feature_matrix.values; selected_features = self.feature_columns\n",
        "        processed_df = pd.DataFrame(processed_matrix, columns=selected_features, index=features_df.index).reset_index()\n",
        "        return processed_df\n",
        "\n",
        "\n",
        "# --- process_connectome_data function (no changes needed) ---\n",
        "def process_connectome_data(train_connectome, test_connectome=None):\n",
        "    \"\"\"Processes functional connectome matrices using the improved class-based method.\"\"\"\n",
        "    # [Code same as above]\n",
        "    if train_connectome is None: print(\"Error: Training connectome data not provided.\"); return None, None\n",
        "    print(\"\\nProcessing neuroimaging data (functional connectome)...\")\n",
        "    start_time = time(); processor = ConnectomeProcessor(n_jobs=-1)\n",
        "    train_connectome_features = processor.fit_transform(train_connectome)\n",
        "    if train_connectome_features is not None and 'participant_id' in train_connectome_features.columns: print(f\"Extracted {train_connectome_features.shape[1] - 1} connectome features for training\")\n",
        "    else: print(\"Warning: Training feature extraction failed or did not return participant_id.\")\n",
        "    test_connectome_features = None\n",
        "    if test_connectome is not None:\n",
        "        try:\n",
        "            test_connectome_features = processor.transform(test_connectome)\n",
        "            if test_connectome_features is not None and 'participant_id' in test_connectome_features.columns: print(f\"Extracted {test_connectome_features.shape[1] - 1} connectome features for testing\")\n",
        "            else: print(\"Warning: Test feature extraction failed or did not return participant_id.\")\n",
        "        except Exception as e: print(f\"Error: Failed to process test connectome data: {e}\"); final_cols = processor.final_feature_columns_ if hasattr(processor, 'final_feature_columns_') else []; test_connectome_features = pd.DataFrame(columns=['participant_id'] + final_cols)\n",
        "    elapsed_time = time() - start_time; print(f\"Connectome processing completed in {elapsed_time:.2f} seconds\")\n",
        "    return train_connectome_features, test_connectome_features\n",
        "\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 5. Multimodal Data Fusion\n",
        "# ====================================\n",
        "def multimodal_fusion(train_merged, train_connectome_features, test_merged=None, test_connectome_features=None):\n",
        "    \"\"\"Combine behavioral/clinical data with neuroimaging features\"\"\"\n",
        "    # [Function body same as before]\n",
        "    print(\"\\nPerforming multimodal data fusion...\")\n",
        "    train_multimodal, test_multimodal = None, None\n",
        "    if train_merged is None or train_connectome_features is None or train_connectome_features.empty: print(\"Error: Cannot perform training data fusion\")\n",
        "    else:\n",
        "        conn_feature_cols = [col for col in train_connectome_features.columns if col != 'participant_id']\n",
        "        if not conn_feature_cols: print(\"Warning: No data in connectome features, skipping fusion.\"); train_multimodal = train_merged.copy()\n",
        "        else:\n",
        "            train_multimodal = train_merged.merge(train_connectome_features, on='participant_id', how='inner')\n",
        "            print(f\"Shape after training data fusion: {train_multimodal.shape}\"); print(f\"Added {len(conn_feature_cols)} connectome features\")\n",
        "            n_lost = len(train_merged) - len(train_multimodal);\n",
        "            if n_lost > 0: print(f\"Warning: {n_lost} participants lost during training fusion\")\n",
        "    if test_merged is not None and test_connectome_features is not None and not test_connectome_features.empty:\n",
        "        conn_feature_cols_test = [col for col in test_connectome_features.columns if col != 'participant_id']\n",
        "        if not conn_feature_cols_test: print(\"Warning: No data in test connectome features, skipping fusion.\"); test_multimodal = test_merged.copy()\n",
        "        else:\n",
        "            test_multimodal = test_merged.merge(test_connectome_features, on='participant_id', how='inner')\n",
        "            print(f\"Shape after test data fusion: {test_multimodal.shape}\")\n",
        "            n_lost = len(test_merged) - len(test_multimodal);\n",
        "            if n_lost > 0: print(f\"Warning: {n_lost} participants lost during test fusion\")\n",
        "    elif test_merged is not None: print(\"Warning: Failed to fuse test data.\"); test_multimodal = test_merged.copy()\n",
        "    return train_multimodal, test_multimodal\n",
        "\n",
        "# ====================================\n",
        "# 7. Feature Engineering and Preprocessing\n",
        "# ====================================\n",
        "def feature_engineering(train_merged, test_merged=None):\n",
        "    \"\"\"Performs feature engineering and preprocessing, properly handling numerical and categorical features.\"\"\"\n",
        "    print(\"\\nPerforming feature engineering...\")\n",
        "    X_train_processed, y_train, X_test_processed, preprocessor, feature_names_out = None, None, None, None, None\n",
        "    if train_merged is None or train_merged.empty:\n",
        "        print(\"Error: Training data is missing\")\n",
        "        return X_train_processed, y_train, X_test_processed, preprocessor, feature_names_out\n",
        "\n",
        "    # --- Operate directly on the passed train_merged ---\n",
        "    target_cols = [col for col in ['ADHD_Outcome', 'Sex_F'] if col in train_merged.columns]\n",
        "    if not target_cols:\n",
        "        print(\"Warning: Target variables not found\")\n",
        "        y_train = None\n",
        "    else:\n",
        "        y_train = train_merged[target_cols]\n",
        "        print(f\"Training targets shape: {y_train.shape}\")\n",
        "\n",
        "    drop_cols = ['participant_id'] + target_cols\n",
        "    # Keep all non-dropped columns as the initial feature pool\n",
        "    X_train = train_merged.drop(columns=drop_cols, errors='ignore')\n",
        "\n",
        "    # --- Process test set ---\n",
        "    X_test = None\n",
        "    if test_merged is not None:\n",
        "        # Check and align columns (based on X_train's columns) - keep all columns from X_train\n",
        "        train_cols = X_train.columns.tolist()\n",
        "        test_merged_aligned = test_merged.copy()\n",
        "        # Drop extra columns in the test set that are not in the training set (except for participant_id)\n",
        "        extra_cols_in_test = [col for col in test_merged_aligned.columns if col not in train_cols and col != 'participant_id']\n",
        "        if extra_cols_in_test:\n",
        "            print(f\"Warning: Extra columns in test set will be dropped: {extra_cols_in_test}\")\n",
        "            test_merged_aligned.drop(columns=extra_cols_in_test, errors='ignore', inplace=True)\n",
        "\n",
        "        # Check if the test set is missing columns from the training set\n",
        "        missing_cols_in_test = [col for col in train_cols if col not in test_merged_aligned.columns]\n",
        "        if missing_cols_in_test:\n",
        "            print(f\"Warning: Test set is missing columns from the training set: {missing_cols_in_test}. These columns will be created and filled with NaN.\")\n",
        "            for col in missing_cols_in_test:\n",
        "                test_merged_aligned[col] = np.nan  # Fill with NaN, IterativeImputer will handle it\n",
        "\n",
        "        # Ensure the column order of the test set is consistent with the training set\n",
        "        X_test = test_merged_aligned[train_cols]\n",
        "        print(f\"Test features shape after alignment: {X_test.shape}\")\n",
        "\n",
        "    # --- Identify Feature Types (Updated) ---\n",
        "    # Explicitly list features to be treated as categorical\n",
        "    # Assume these are columns from the original categorical metadata, retaining their original names after the merge\n",
        "    categorical_features_list = [\n",
        "        'Basic_Demos_Gender',  # May need adjustment based on the actual column name if it's not Sex_F\n",
        "        'Barratt_Barratt_P1_Edu',\n",
        "        'Barratt_Barratt_P1_Occ',\n",
        "        'Barratt_Barratt_P2_Edu',\n",
        "        'Barratt_Barratt_P2_Occ',\n",
        "        # Add other columns that need to be treated as categorical, check the columns of train_categorical\n",
        "    ]\n",
        "\n",
        "    # Filter out columns from the original feature pool that actually exist and belong to the categorical list\n",
        "    categorical_features = [col for col in categorical_features_list if col in X_train.columns]\n",
        "    # The rest are considered numerical features (excluding those identified as categorical)\n",
        "    numeric_features = [col for col in X_train.columns if col not in categorical_features]\n",
        "\n",
        "    print(f\"Identified numerical features: {len(numeric_features)}, Identified categorical features: {len(categorical_features)}\")\n",
        "\n",
        "    if not numeric_features and not categorical_features:\n",
        "        print(\"Error: No features found\")\n",
        "        return None, y_train, None, None, None\n",
        "    # Note: IterativeImputer is mainly for numerical features. If there are only categorical features, this pipeline needs adjustment.\n",
        "    # If there are indeed no numerical features but there are categorical ones, they need to be handled separately. Currently, it's assumed there are at least some numerical features.\n",
        "    if not numeric_features:\n",
        "        print(\"Warning: No numerical features found, IterativeImputer may not work. Please check the feature list and data.\")  # Continue, but may error out\n",
        "\n",
        "    # --- Create Preprocessing Pipeline (Updated) ---\n",
        "    # Numerical feature pipeline: IterativeImputer + StandardScaler\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', IterativeImputer(estimator=LassoCV(random_state=SEED), max_iter=5, random_state=SEED)),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Categorical feature pipeline: SimpleImputer (for categories) + OneHotEncoder\n",
        "    # Use SimpleImputer to fill missing values in categorical features (with a constant or the most frequent value)\n",
        "    # handle_unknown='ignore' to handle categories in the test set that were not seen in the training set\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Use most frequent value instead\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "    # Use ColumnTransformer to combine different types of processing\n",
        "    # remainder='passthrough' to keep columns not listed in transformers (if needed, though they are usually all listed here)\n",
        "    # Or remainder='drop' to drop unlisted columns (the original behavior)\n",
        "    transformers_list = []\n",
        "    if numeric_features:\n",
        "        transformers_list.append(('num', numeric_transformer, numeric_features))\n",
        "    if categorical_features:\n",
        "        transformers_list.append(('cat', categorical_transformer, categorical_features))\n",
        "\n",
        "    if not transformers_list:\n",
        "        print(\"Error: No features were selected in the preprocessor.\")\n",
        "        return None, y_train, None, None, None\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=transformers_list,\n",
        "        remainder='passthrough'  # Or set to 'drop' as needed\n",
        "    )\n",
        "\n",
        "    # --- Apply Preprocessing ---\n",
        "    print(\"Applying preprocessing pipeline...\")\n",
        "    try:\n",
        "        # Ensure fit_transform only fits on the training data\n",
        "        X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "        # Get feature names after processing\n",
        "        # Need to ensure the preprocessor can get feature names; for OneHotEncoder, this usually requires specifying categories='auto' or providing a list of categories\n",
        "        try:\n",
        "            feature_names_out = preprocessor.get_feature_names_out()\n",
        "        except Exception as name_e:\n",
        "            print(f\"Warning: Could not get feature names: {name_e}. Feature names will be the default names generated by ColumnTransformer.\")\n",
        "            # fallback to default names if get_feature_names_out fails\n",
        "            if hasattr(preprocessor, 'transformers_'):\n",
        "                current_feature_names = []\n",
        "                for name, trans, cols in preprocessor.transformers_:\n",
        "                    if trans == 'passthrough':\n",
        "                        current_feature_names.extend(cols)\n",
        "                    elif hasattr(trans, 'get_feature_names_out'):\n",
        "                        # Handle pipelines within ColumnTransformer\n",
        "                        if isinstance(trans, Pipeline):\n",
        "                            # Try to get names from the last step or the encoder if present\n",
        "                            last_step = trans.steps[-1][1]\n",
        "                            if hasattr(last_step, 'get_feature_names_out'):\n",
        "                                # get_feature_names_out requires input_features for OneHotEncoder in Pipeline\n",
        "                                # This is tricky within ColumnTransformer. Simple fallback might be needed.\n",
        "                                try:\n",
        "                                    step_names = last_step.get_feature_names_out(cols)\n",
        "                                    current_feature_names.extend(step_names)\n",
        "                                except:  # If get_feature_names_out needs input_features, fallback\n",
        "                                    print(\"   Fallback: Using ColumnTransformer default names.\")\n",
        "                                    feature_names_out = preprocessor.get_feature_names_out()  # Try the main method\n",
        "                                    break  # Stop manual attempt\n",
        "\n",
        "                        else:  # For other transformers directly in ColumnTransformer\n",
        "                            step_names = trans.get_feature_names_out(cols)\n",
        "                            current_feature_names.extend(step_names)\n",
        "\n",
        "                if 'feature_names_out' not in locals() or feature_names_out is None:\n",
        "                    feature_names_out = current_feature_names  # Use collected names if main method failed\n",
        "\n",
        "        # If still no feature names (e.g. only VarianceThreshold) or mismatch\n",
        "        if feature_names_out is None or len(feature_names_out) != X_train_preprocessed.shape[1]:\n",
        "            print(\"Warning: Could not reliably get feature names, using default generated names.\")\n",
        "            feature_names_out = [f'feature_{i}' for i in range(X_train_preprocessed.shape[1])]\n",
        "\n",
        "        X_train_processed = pd.DataFrame(X_train_preprocessed, index=X_train.index, columns=feature_names_out)\n",
        "        print(f\"Training features shape: {X_train_processed.shape}\")\n",
        "\n",
        "        if X_test is not None:\n",
        "            # Ensure transform uses the fitted preprocessor\n",
        "            X_test_preprocessed = preprocessor.transform(X_test)\n",
        "            # Test set uses the same feature names as the training set\n",
        "            X_test_processed = pd.DataFrame(X_test_preprocessed, index=X_test.index, columns=feature_names_out)\n",
        "            print(f\"Test features shape: {X_test_processed.shape}\")\n",
        "        else:\n",
        "            X_test_processed = None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in feature engineering/preprocessing: {e}\")\n",
        "        # Fallback: Return original data if processing fails (might cause later errors but allows pipeline to continue)\n",
        "        # Or return None/empty as before if failure is critical\n",
        "        return None, y_train, None, None, None  # Keep original failure handling\n",
        "\n",
        "    return X_train_processed, y_train, X_test_processed, preprocessor, feature_names_out\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 4. Feature Selection\n",
        "# ====================================\n",
        "def select_features(X_train, y_train, n_features=30): # Default changed to 20\n",
        "    \"\"\"Performs feature selection using Random Forest feature importance\"\"\"\n",
        "    print(\"\\nPerforming feature selection...\")\n",
        "    if X_train is None or y_train is None or y_train.shape[1] == 0:\n",
        "        print(\"Warning: Missing training data or target variables, cannot perform feature selection.\")\n",
        "        return None, {} if X_train is None else X_train.columns.tolist(), {}\n",
        "\n",
        "    selected_features_dict = {}\n",
        "    all_selected_set = set()\n",
        "\n",
        "    for target in y_train.columns:\n",
        "        print(f\"\\nSelecting features for {target}:\")\n",
        "        if X_train.empty: print(f\"Warning: X_train is empty, cannot select features for {target}.\"); continue\n",
        "\n",
        "        try:\n",
        "            rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "            rf.fit(X_train, y_train[target])\n",
        "\n",
        "            importances = pd.DataFrame({\n",
        "                'feature': X_train.columns,\n",
        "                'importance': rf.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Ensure n_features is not greater than the number of available features\n",
        "            actual_n_features = min(n_features, len(X_train.columns))\n",
        "            top_features = importances.head(actual_n_features)['feature'].tolist()\n",
        "            selected_features_dict[target] = top_features\n",
        "            all_selected_set.update(top_features)\n",
        "\n",
        "            print(f\"Top {len(top_features)} features selected for {target}\")\n",
        "            print(\"Top 5 important features:\")\n",
        "            for i, feat in enumerate(top_features[:5], 1):\n",
        "                imp = importances.loc[importances['feature'] == feat, 'importance'].values[0]\n",
        "                print(f\"{i}. {feat}: {imp:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error selecting features for {target}: {e}\")\n",
        "            selected_features_dict[target] = X_train.columns.tolist() # Keep all features if an error occurs\n",
        "            all_selected_set.update(X_train.columns.tolist())\n",
        "\n",
        "\n",
        "    all_selected = list(all_selected_set)\n",
        "    print(f\"\\nSelected a total of {len(all_selected)} unique features\")\n",
        "\n",
        "    return all_selected, selected_features_dict\n",
        "\n",
        "# ====================================\n",
        "# 8. Inverse Probability Weighting\n",
        "# ====================================\n",
        "def calculate_optimized_weights(y_train,\n",
        "                                female_adhd_boost=2.0,\n",
        "                                female_non_adhd_boost=1.5,\n",
        "                                male_non_adhd_boost=1.2,\n",
        "                                male_adhd_boost=1.0):\n",
        "    \"\"\"Optimizes sample weights using IPW, allowing adjustment of boost factors.\"\"\"\n",
        "    print(\"\\nCalculating inverse probability weighting sample weights (adjustable factors)...\")\n",
        "\n",
        "    if y_train is None or 'ADHD_Outcome' not in y_train.columns or 'Sex_F' not in y_train.columns:\n",
        "        print(\"Warning: Cannot calculate weights\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        ADHD_Outcome = y_train['ADHD_Outcome'].values\n",
        "        Sex_F = y_train['Sex_F'].values\n",
        "    except KeyError as e:\n",
        "        print(f\"Warning: Target column {e} is missing\")\n",
        "        return None\n",
        "\n",
        "    combined_target = ADHD_Outcome * 2 + Sex_F\n",
        "    class_counts = np.bincount(combined_target, minlength=4)\n",
        "    total_samples = len(combined_target)\n",
        "\n",
        "    if total_samples == 0:\n",
        "        print(\"Warning: Number of samples is 0\")\n",
        "        return None\n",
        "\n",
        "    print(\"Class distribution:\")\n",
        "    class_desc_map = {\n",
        "        0: \"Non-ADHD Male\",\n",
        "        1: \"Non-ADHD Female\",\n",
        "        2: \"ADHD Male\",\n",
        "        3: \"ADHD Female\"\n",
        "    }\n",
        "\n",
        "    boost_map = {\n",
        "        0: male_non_adhd_boost,\n",
        "        1: female_non_adhd_boost,\n",
        "        2: male_adhd_boost,\n",
        "        3: female_adhd_boost\n",
        "    }\n",
        "\n",
        "    for class_val, count in enumerate(class_counts):\n",
        "        print(f\"  Class {class_val} ({class_desc_map.get(class_val, '?')}): {count} samples\")\n",
        "\n",
        "    weights = np.ones(total_samples)\n",
        "    base_weights = {}\n",
        "\n",
        "    for class_val, count in enumerate(class_counts):\n",
        "        if count == 0:\n",
        "            base_weights[class_val] = 0\n",
        "            continue\n",
        "\n",
        "        boost_factor = boost_map.get(class_val, 1.0)\n",
        "        class_weight = boost_factor * total_samples / count\n",
        "        base_weights[class_val] = class_weight\n",
        "        weights[combined_target == class_val] = class_weight\n",
        "\n",
        "    mean_weight = np.mean(weights)\n",
        "\n",
        "    if mean_weight > 0:\n",
        "        weights = weights / mean_weight\n",
        "        print(f\"\\nWeights have been normalized\")\n",
        "    else:\n",
        "        print(\"\\nWarning: Cannot normalize weights\")\n",
        "\n",
        "    print(f\"Total samples: {total_samples}\")\n",
        "    print(f\"Number of female ADHD samples: {class_counts[3]}\")\n",
        "\n",
        "    print(f\"Using weight coefficients:\")\n",
        "    print(f\"  - ADHD Female(3): {female_adhd_boost:.2f}x\")\n",
        "    print(f\"  - Non-ADHD Female(1): {female_non_adhd_boost:.2f}x\")\n",
        "    print(f\"  - Non-ADHD Male(0): {male_non_adhd_boost:.2f}x\")\n",
        "    print(f\"  - ADHD Male(2): {male_adhd_boost:.2f}x\")\n",
        "\n",
        "    print(\"\\nFinal average weights:\")\n",
        "    for class_val in range(len(class_counts)):\n",
        "        mask = (combined_target == class_val)\n",
        "        if np.sum(mask) > 0:\n",
        "            avg_w = np.mean(weights[mask])\n",
        "            print(f\"  Class {class_val} ({class_desc_map.get(class_val, '?')}): {avg_w:.4f}\")\n",
        "        else:\n",
        "            print(f\"  Class {class_val} ({class_desc_map.get(class_val, '?')}): N/A\")\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "\n",
        "# --- Optuna Objective Functions ---\n",
        "from sklearn.model_selection import StratifiedKFold # Already imported, but reiterated here to ensure visibility\n",
        "from sklearn.model_selection import cross_val_score # cross_val_score is no longer used directly in the function, but the import can be kept\n",
        "\n",
        "def objective_lr(trial, X, y, sample_weights):\n",
        "    \"\"\"Optuna objective function for Logistic Regression (Revised).\"\"\"\n",
        "    # Fix: Suggest penalty and solver parameters independently to avoid dynamic space errors\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
        "    C = trial.suggest_float('C', 0.01, 10, log=True)\n",
        "\n",
        "    # Check for incompatible combinations and return a low score\n",
        "    # Common compatibility issues:\n",
        "    # 'lbfgs', 'newton-cg', 'sag', 'saga' only support 'l2' or None penalty\n",
        "    # 'liblinear' supports 'l1' and 'l2'\n",
        "    # 'saga' and 'liblinear' support 'l1'\n",
        "    # Note: Your code uses class_weight='balanced', which is often mutually exclusive with or requires careful use alongside sample_weight.\n",
        "    # If used simultaneously, sample_weight will be multiplied by class_weight. The original setting is kept here, but be aware.\n",
        "    incompatible = False\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        incompatible = True\n",
        "    if penalty == 'l2' and solver == 'liblinear': # liblinear supports l2, this might be fine based on original param_dist\n",
        "        # If you want to exclude liblinear for l2 based on preference, set incompatible=True\n",
        "        pass # Keep liblinear for l2 as it was in original param_dist\n",
        "\n",
        "    if incompatible:\n",
        "        # print(f\"Info: Skipping incompatible LR params: penalty={penalty}, solver={solver}\")\n",
        "        return 0.0 # Return a low score for incompatible combinations\n",
        "\n",
        "    # Instantiate model\n",
        "    model = LogisticRegression(\n",
        "        C=C,\n",
        "        penalty=penalty,\n",
        "        solver=solver,\n",
        "        random_state=42,\n",
        "        max_iter=5000, # Increase max_iter, especially for sag/saga solvers, to ensure convergence\n",
        "        class_weight='balanced' # Continue to use, but sample_weight will further adjust the total weight\n",
        "    )\n",
        "\n",
        "    # --- Manual Cross-Validation for Evaluation ---\n",
        "    # Replace cross_val_score to manually pass sample_weight\n",
        "    cv_scores = []\n",
        "    # Use the same number of splits and random_state as the outer CV, but ensure it's an independent KFold instance\n",
        "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # The 3 folds here are the same as in the original RandomizedSearchCV\n",
        "\n",
        "    try:\n",
        "        for fold, (train_idx, val_idx) in enumerate(inner_cv.split(X, y, groups=y)): # Use y for stratification\n",
        "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            fold_weights = sample_weights[train_idx] if sample_weights is not None else None\n",
        "\n",
        "            # Clone the model to ensure independent training for each fold, and set the random state\n",
        "            fold_model = clone(model)\n",
        "            if hasattr(fold_model, 'random_state'):\n",
        "                fold_model.random_state = 42 + fold # Set a different random state for each fold\n",
        "\n",
        "            # Train the model, manually passing sample_weight\n",
        "            # Note: LogisticRegression's fit method directly accepts sample_weight\n",
        "            fit_params_fold = {}\n",
        "            if fold_weights is not None:\n",
        "                fit_params_fold['sample_weight'] = fold_weights\n",
        "\n",
        "            fold_model.fit(X_train_fold, y_train_fold, **fit_params_fold)\n",
        "\n",
        "            # Evaluate model (using AUC)\n",
        "            y_pred_proba = fold_model.predict_proba(X_val_fold)[:, 1]\n",
        "            if len(np.unique(y_val_fold)) < 2:\n",
        "                # If the validation set has only one class, AUC cannot be calculated, skip this fold or return a low score\n",
        "                # print(f\"Info: Skipping LR fold {fold} due to single class in validation set.\")\n",
        "                continue # Skip the current fold\n",
        "\n",
        "            score = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "            cv_scores.append(score)\n",
        "\n",
        "        if not cv_scores: # If all folds were skipped (e.g., too little data or stratification issues)\n",
        "            # print(\"Warning: LR tuning failed, no valid CV scores.\")\n",
        "            return 0.0 # Return a low score\n",
        "\n",
        "        return np.mean(cv_scores) # Return the average AUC\n",
        "\n",
        "    except Exception as e:\n",
        "        # If other errors occur during training or evaluation\n",
        "        # print(f\"Warning: LR trial failed during CV with params {trial.params}: {e}\")\n",
        "        return 0.0 # Return a low score\n",
        "\n",
        "def objective_rf(trial, X, y, sample_weights):\n",
        "    \"\"\"Optuna objective function for RandomForestClassifier (Revised).\"\"\"\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 20) # None can be indirectly searched by setting a large range\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None, 0.6, 0.8, 1.0])\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced' # RF's class_weight is usually used in conjunction with sample weights\n",
        "    )\n",
        "\n",
        "    # --- Manual Cross-Validation for Evaluation ---\n",
        "    cv_scores = []\n",
        "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    try:\n",
        "        for fold, (train_idx, val_idx) in enumerate(inner_cv.split(X, y, groups=y)):\n",
        "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            fold_weights = sample_weights[train_idx] if sample_weights is not None else None\n",
        "\n",
        "            fold_model = clone(model)\n",
        "            if hasattr(fold_model, 'random_state'):\n",
        "                fold_model.random_state = 42 + fold\n",
        "\n",
        "            # Train the model, manually passing sample_weight\n",
        "            # Note: RandomForestClassifier's fit method directly accepts sample_weight\n",
        "            fit_params_fold = {}\n",
        "            if fold_weights is not None:\n",
        "                fit_params_fold['sample_weight'] = fold_weights\n",
        "\n",
        "            fold_model.fit(X_train_fold, y_train_fold, **fit_params_fold)\n",
        "\n",
        "            # Evaluate model (using AUC)\n",
        "            y_pred_proba = fold_model.predict_proba(X_val_fold)[:, 1]\n",
        "            if len(np.unique(y_val_fold)) < 2:\n",
        "                # print(f\"Info: Skipping RF fold {fold} due to single class in validation set.\")\n",
        "                continue\n",
        "\n",
        "            score = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "            cv_scores.append(score)\n",
        "\n",
        "        if not cv_scores:\n",
        "            # print(\"Warning: RF tuning failed, no valid CV scores.\")\n",
        "            return 0.0\n",
        "\n",
        "        return np.mean(cv_scores)\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Warning: RF trial failed during CV with params {trial.params}: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "def objective_xgb(trial, X, y, sample_weights):\n",
        "    \"\"\"Optuna objective function for XGBoost (Revised).\"\"\"\n",
        "    # The parameter search range can be adjusted as needed\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 0.5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
        "        # Imbalance handling parameter, very important\n",
        "        # scale_pos_weight = count(negative class) / count(positive class)\n",
        "        # Or you can manually calculate or adjust it based on the value suggested by the Trial\n",
        "        # If you want Optuna to optimize this value itself, use suggest_float\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 10.0, log=True)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='auc',\n",
        "        use_label_encoder=False,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    # --- Manual Cross-Validation for Evaluation ---\n",
        "    cv_scores = []\n",
        "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    try:\n",
        "        for fold, (train_idx, val_idx) in enumerate(inner_cv.split(X, y, groups=y)):\n",
        "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            fold_weights = sample_weights[train_idx] if sample_weights is not None else None\n",
        "\n",
        "            fold_model = clone(model)\n",
        "            if hasattr(fold_model, 'random_state'):\n",
        "                fold_model.random_state = 42 + fold\n",
        "\n",
        "            # Train the model, manually passing sample_weight\n",
        "            # Note: XGBoost's fit method directly accepts sample_weight\n",
        "            fit_params_fold = {}\n",
        "            if fold_weights is not None:\n",
        "                fit_params_fold['sample_weight'] = fold_weights\n",
        "\n",
        "            # For XGBoost, eval_set and early_stopping_rounds can be provided in fit, but are not supported by cross_val_score\n",
        "            # Early stopping can be implemented in manual CV, but it would make the code more complex. Here, for simplicity, only sample_weight is kept as a fit parameter\n",
        "            fold_model.fit(X_train_fold, y_train_fold, **fit_params_fold)\n",
        "\n",
        "\n",
        "            # Evaluate model (using AUC)\n",
        "            y_pred_proba = fold_model.predict_proba(X_val_fold)[:, 1]\n",
        "            if len(np.unique(y_val_fold)) < 2:\n",
        "                # print(f\"Info: Skipping XGB fold {fold} due to single class in validation set.\")\n",
        "                continue\n",
        "\n",
        "            score = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "            cv_scores.append(score)\n",
        "\n",
        "        if not cv_scores:\n",
        "            # print(\"Warning: XGB tuning failed, no valid CV scores.\")\n",
        "            return 0.0\n",
        "\n",
        "        return np.mean(cv_scores)\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Warning: XGB trial failed during CV with params {trial.params}: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "def objective_lgbm(trial, X, y, sample_weights):\n",
        "    \"\"\"Optuna objective function for LightGBM.\"\"\"\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        # Modify these two lines, change the lower bound from 0.0 to 0.001 or remove log=True\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0, log=True),\n",
        "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.5),\n",
        "        'is_unbalance': True  # Handle imbalanced datasets\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        objective='binary',\n",
        "        metric='auc',\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    # --- Manual Cross-Validation for Evaluation ---\n",
        "    cv_scores = []\n",
        "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    try:\n",
        "        for fold, (train_idx, val_idx) in enumerate(inner_cv.split(X, y, groups=y)):\n",
        "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
        "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "            fold_weights = sample_weights[train_idx] if sample_weights is not None else None\n",
        "\n",
        "            fold_model = clone(model)\n",
        "            if hasattr(fold_model, 'random_state'):\n",
        "                fold_model.random_state = 42 + fold\n",
        "\n",
        "            # Train model\n",
        "            fit_params_fold = {}\n",
        "            if fold_weights is not None:\n",
        "                fit_params_fold['sample_weight'] = fold_weights\n",
        "\n",
        "            fold_model.fit(X_train_fold, y_train_fold, **fit_params_fold)\n",
        "\n",
        "            # Evaluate model\n",
        "            y_pred_proba = fold_model.predict_proba(X_val_fold)[:, 1]\n",
        "            if len(np.unique(y_val_fold)) < 2:\n",
        "                continue\n",
        "\n",
        "            score = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "            cv_scores.append(score)\n",
        "\n",
        "        if not cv_scores:\n",
        "            return 0.0\n",
        "\n",
        "        return np.mean(cv_scores)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"LGBM error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# Map objective functions to model names for easy use in train_models_with_cv\n",
        "objective_map = {\n",
        "    'logistic': objective_lr,\n",
        "    'rf': objective_rf,\n",
        "    'xgb': objective_xgb,\n",
        "    'lgbm': objective_lgbm # <-- Ensure this line exists\n",
        "}\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 9. Model Training and Evaluation\n",
        "# ====================================\n",
        "\n",
        "# --- Helper Function: Find Optimal Threshold [Unchanged] ---\n",
        "def find_optimal_threshold(y_true, y_pred_proba, metric='f1'):\n",
        "    # [Function body same as before]\n",
        "    thresholds = np.linspace(0.01, 0.99, 100); best_score = -1; best_threshold = 0.5\n",
        "    if metric == 'f1':\n",
        "        y_true_int = np.array(y_true).astype(int)\n",
        "        with np.errstate(divide='ignore', invalid='ignore'): scores = [f1_score(y_true_int, (y_pred_proba >= t).astype(int), zero_division=0) for t in thresholds]\n",
        "        if np.all(np.isnan(scores)) or not np.any(scores): print(f\"  Warning: Could not calculate a valid F1 score\"); return 0.5\n",
        "        best_idx = np.nanargmax(scores); best_score = scores[best_idx]; best_threshold = thresholds[best_idx]\n",
        "    print(f\"  Optimal threshold ({metric.upper()}): {best_threshold:.4f} (Score: {best_score:.4f})\")\n",
        "    return best_threshold\n",
        "\n",
        "# --- Main Training Function with Tuning and Repeated CV for OOF ---\n",
        "def train_models_with_cv(X_train, y_train, selected_features_dict,\n",
        "                         target_to_process=None,\n",
        "                         sample_weights=None,\n",
        "                         n_splits=5,\n",
        "                         n_repeats=5,\n",
        "                         n_tuning_iter=50,\n",
        "                         inner_cv_folds=3):\n",
        "    \"\"\"\n",
        "    Trains and evaluates models using hyperparameter tuning and repeated stratified K-fold cross-validation.\n",
        "    \"\"\"\n",
        "    print(f\"\\nStarting model training with {n_repeats} repeats of {n_splits}-Fold CV and Tuning ({n_tuning_iter} iterations)...\")\n",
        "    if target_to_process: print(f\"  Processing specific targets: {target_to_process}\")\n",
        "\n",
        "    final_models = {}\n",
        "    tuning_results = {}\n",
        "    oof_predictions = {} # Store the final averaged OOF predictions\n",
        "\n",
        "    # --- Model and Parameter Definitions ---\n",
        "    rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
        "    rf_param_dist = {'n_estimators': randint(100, 500), 'max_depth': [5, 10, 15, 20, None], 'min_samples_split': randint(2, 11), 'min_samples_leaf': randint(1, 11), 'max_features': ['sqrt', 'log2', None]}\n",
        "\n",
        "    lr_model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced', max_iter=1000)\n",
        "    lr_param_dist = { 'C': uniform(0.01, 10), 'penalty': ['l1', 'l2'] }\n",
        "\n",
        "    xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc', use_label_encoder=False, random_state=42, n_jobs=-1)\n",
        "    xgb_param_dist = {'n_estimators': randint(100, 1000), 'learning_rate': uniform(0.01, 0.19), 'max_depth': randint(3, 8), 'subsample': uniform(0.6, 0.4), 'colsample_bytree': uniform(0.6, 0.4), 'gamma': uniform(0, 0.5), 'reg_alpha': uniform(0, 1), 'reg_lambda': uniform(0, 1)}\n",
        "\n",
        "    lgbm_model = lgb.LGBMClassifier(random_state=SEED, n_jobs=-1)\n",
        "\n",
        "    base_models = {'rf': rf_model, 'logistic': lr_model, 'xgb': xgb_model, 'lgbm': lgbm_model}\n",
        "\n",
        "    # --- Determine Targets to Process ---\n",
        "    targets_in_data = y_train.columns.tolist()\n",
        "    if target_to_process:\n",
        "        targets_to_run = [t for t in target_to_process if t in targets_in_data]\n",
        "        if not targets_to_run: print(\"Error: Specified targets are not in the data.\"); return {}, {}, {}\n",
        "    else:\n",
        "        targets_to_run = targets_in_data\n",
        "\n",
        "    # --- Process Each Target ---\n",
        "    for target in targets_to_run:\n",
        "        print(f\"\\n--- Processing Target: {target} ---\")\n",
        "\n",
        "        # --- Feature Selection ---\n",
        "        if target not in selected_features_dict or not selected_features_dict[target]:\n",
        "            features_for_target = X_train.columns.tolist()\n",
        "            print(f\"Warning: No features for {target}, using all {len(features_for_target)}.\")\n",
        "        else:\n",
        "            features_for_target = [f for f in selected_features_dict[target] if f in X_train.columns]\n",
        "\n",
        "        if not features_for_target:\n",
        "            print(f\"Error: No valid features for {target}.\")\n",
        "            continue\n",
        "\n",
        "        missing_in_train = [f for f in features_for_target if f not in X_train.columns]\n",
        "        if missing_in_train:\n",
        "            print(f\"Error! X_train is missing features: {missing_in_train}.\")\n",
        "            continue\n",
        "\n",
        "        X_target_full = X_train[features_for_target]\n",
        "        y_target = y_train[target]\n",
        "        print(f\"  Using {len(features_for_target)} features for {target}.\")\n",
        "\n",
        "        # --- Hyperparameter Tuning - Using Optuna ---\n",
        "        print(f\"  Tuning hyperparameters using Optuna ({n_tuning_iter} trials)...\")\n",
        "        best_overall_auc = -1  # To track the best AUC among different models\n",
        "        best_model_name = None\n",
        "        best_params = None  # Store the parameters of the best model\n",
        "        target_tuning_results = {}  # Store the best result for each model\n",
        "\n",
        "        models_to_tune = list(base_models.keys())\n",
        "        print(f\"    Models to tune: {models_to_tune}\")\n",
        "\n",
        "        for name in models_to_tune:\n",
        "            print(f\"    Tuning {name}...\")\n",
        "            objective_func = objective_map.get(name)  # Get the corresponding objective function\n",
        "\n",
        "            if objective_func is None:\n",
        "                print(f\"    Error: No Optuna objective function defined for {name}. Skipping.\")\n",
        "                target_tuning_results[name] = {'best_score': 0, 'best_params': None}\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Create Optuna Study, maximizing AUC\n",
        "                study = optuna.create_study(\n",
        "                    direction='maximize',\n",
        "                    study_name=f\"{target}_{name}_tuning\",\n",
        "                    load_if_exists=False\n",
        "                )\n",
        "\n",
        "                # Run optimization, passing X, y, and sample_weights to the objective function\n",
        "                study.optimize(\n",
        "                    lambda trial: objective_func(trial, X_target_full, y_target, sample_weights),\n",
        "                    n_trials=n_tuning_iter,\n",
        "                    show_progress_bar=True\n",
        "                )\n",
        "\n",
        "                # Get the best result for the current model\n",
        "                current_best_auc = study.best_value\n",
        "                current_best_params = study.best_params\n",
        "\n",
        "                print(f\"      Best AUC for {name}: {current_best_auc:.4f}\")\n",
        "\n",
        "                target_tuning_results[name] = {'best_score': current_best_auc, 'best_params': current_best_params}\n",
        "\n",
        "                # Update the overall best model and parameters\n",
        "                if current_best_auc > best_overall_auc:\n",
        "                    best_overall_auc = current_best_auc\n",
        "                    best_model_name = name\n",
        "                    best_params = current_best_params\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error during Optuna tuning for {name}: {e}\")\n",
        "                target_tuning_results[name] = {'best_score': 0.0, 'best_params': None}\n",
        "\n",
        "        tuning_results[target] = target_tuning_results  # Store the tuning results for all models\n",
        "\n",
        "        # Create the best model instance based on the stored best model name and parameters\n",
        "        if best_model_name is None or best_params is None:\n",
        "            print(f\"Error: Optuna tuning failed for {target}. Could not find a best model.\")\n",
        "            continue  # Skip subsequent steps for the current target\n",
        "\n",
        "        print(f\"\\n  Selected best model: {best_model_name} (Tuning AUC: {best_overall_auc:.4f})\")\n",
        "\n",
        "        # Instantiate the best model for subsequent OOF and final training\n",
        "        base_model_instance = base_models[best_model_name]\n",
        "\n",
        "        if isinstance(base_model_instance, LogisticRegression):\n",
        "            best_estimator = LogisticRegression(random_state=SEED, max_iter=1000, class_weight='balanced', **best_params)\n",
        "        elif isinstance(base_model_instance, RandomForestClassifier):\n",
        "            best_estimator = RandomForestClassifier(random_state=SEED, n_jobs=-1, class_weight='balanced', **best_params)\n",
        "        elif isinstance(base_model_instance, xgb.XGBClassifier):\n",
        "            # XGBoost usually includes all parameters in params\n",
        "            best_estimator = xgb.XGBClassifier(\n",
        "                objective='binary:logistic',\n",
        "                eval_metric='auc',\n",
        "                use_label_encoder=False,\n",
        "                random_state=SEED,\n",
        "                n_jobs=-1,\n",
        "                **best_params\n",
        "            )\n",
        "        # Add instantiation branch for LightGBM\n",
        "        elif isinstance(base_model_instance, lgb.LGBMClassifier): # <-- Ensure this line exists\n",
        "            best_estimator = lgb.LGBMClassifier( # <-- Ensure this line exists\n",
        "                random_state=SEED, # <-- Ensure this line exists\n",
        "                n_jobs=-1, # <-- Ensure this line exists\n",
        "                objective='binary', # <-- Ensure this line exists\n",
        "                metric='auc', # <-- Ensure this line exists\n",
        "                verbose=-1, # <-- Ensure this line exists\n",
        "                **best_params # <-- Ensure this line exists\n",
        "            ) # <-- Ensure this line exists\n",
        "        else:\n",
        "            print(f\"Error: Unknown best model type {best_model_name}. Cannot instantiate.\")\n",
        "            final_models[target] = {'model': None, 'features': features_for_target, 'threshold': optimal_threshold, 'auc': final_cv_mean_auc, 'model_name': best_model_name}\n",
        "            continue  # Skip subsequent steps for the current target\n",
        "\n",
        "        # --- Outer CV to get OOF predictions (using RepeatedStratifiedKFold) ---\n",
        "        print(f\"  Generating OOF predictions ({n_repeats} repeats of {n_splits}-fold CV)...\")\n",
        "        oof_preds_sum = np.zeros(len(X_target_full))\n",
        "        oof_counts = np.zeros(len(X_target_full))\n",
        "\n",
        "        outer_cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
        "        fold_val_auc_scores = []\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(outer_cv.split(X_target_full, y_target)):\n",
        "            X_train_fold, X_val_fold = X_target_full.iloc[train_idx], X_target_full.iloc[val_idx]\n",
        "            y_train_fold, y_val_fold = y_target.iloc[train_idx], y_target.iloc[val_idx]\n",
        "\n",
        "            fold_weights = sample_weights[train_idx] if sample_weights is not None else None\n",
        "            fold_model = clone(best_estimator)\n",
        "\n",
        "            if hasattr(fold_model, 'random_state'):\n",
        "                fold_model.random_state = 42 + fold\n",
        "\n",
        "            try:\n",
        "                fit_params_outer = {}\n",
        "                # Modify the condition, add handling for LGBMClassifier\n",
        "                if fold_weights is not None and isinstance(fold_model, (LogisticRegression, xgb.XGBClassifier, lgb.LGBMClassifier)):\n",
        "                    fit_params_outer['sample_weight'] = fold_weights\n",
        "\n",
        "                fold_model.fit(X_train_fold, y_train_fold, **fit_params_outer)\n",
        "                fold_pred_proba = fold_model.predict_proba(X_val_fold)[:, 1]\n",
        "\n",
        "                # Accumulate predictions and counts\n",
        "                oof_preds_sum[val_idx] += fold_pred_proba\n",
        "                oof_counts[val_idx] += 1\n",
        "\n",
        "                fold_val_auc = roc_auc_score(y_val_fold, fold_pred_proba)\n",
        "                fold_val_auc_scores.append(fold_val_auc)\n",
        "            except Exception as e:\n",
        "                print(f\"    Error OOF fold {fold+1}: {e}\")\n",
        "                fold_val_auc_scores.append(0.0)\n",
        "\n",
        "        # Calculate the final average OOF predictions\n",
        "        valid_oof_mask = oof_counts > 0\n",
        "        oof_preds_final = np.zeros(len(X_target_full))\n",
        "        oof_preds_final[valid_oof_mask] = oof_preds_sum[valid_oof_mask] / oof_counts[valid_oof_mask]\n",
        "\n",
        "        if not np.all(valid_oof_mask):\n",
        "            print(f\"Warning: {np.sum(~valid_oof_mask)} samples have 0 OOF predictions.\")\n",
        "\n",
        "        oof_predictions[target] = oof_preds_final\n",
        "\n",
        "        # Print the AUC results of the repeated CV\n",
        "        final_cv_mean_auc = np.mean([s for s in fold_val_auc_scores if s > 0]) if any(s > 0 for s in fold_val_auc_scores) else 0.0\n",
        "        final_cv_std_auc = np.std([s for s in fold_val_auc_scores if s > 0]) if any(s > 0 for s in fold_val_auc_scores) else 0.0\n",
        "        print(f\"  Outer {n_repeats}x{n_splits}-Fold CV Mean AUC for {best_model_name}: {final_cv_mean_auc:.4f} (+/- {final_cv_std_auc:.4f})\")\n",
        "\n",
        "        # Find the optimal threshold - based on the averaged oof_preds_final\n",
        "        print(f\"  Finding optimal threshold using averaged OOF predictions...\")\n",
        "        optimal_threshold = find_optimal_threshold(y_target, oof_preds_final, metric='f1')\n",
        "\n",
        "        # Print OOF evaluation metrics - based on the averaged oof_preds_final\n",
        "        print(f\"\\n  Calculating OOF metrics using threshold: {optimal_threshold:.4f}\")\n",
        "        oof_preds_binary = (oof_preds_final >= optimal_threshold).astype(int)\n",
        "\n",
        "        try:\n",
        "            cm = confusion_matrix(y_target, oof_preds_binary)\n",
        "            print(\"  OOF Confusion Matrix:\\n\", cm)\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            print(f\"  TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
        "        except Exception as e_cm:\n",
        "            print(f\"  Error OOF CM: {e_cm}\")\n",
        "\n",
        "        try:\n",
        "            report = classification_report(y_target, oof_preds_binary)\n",
        "            print(\"\\n  OOF Classification Report:\\n\", report)\n",
        "        except Exception as e_report:\n",
        "            print(f\"  Error OOF Report: {e_report}\")\n",
        "\n",
        "        # Train the final model\n",
        "        print(f\"\\n  Training final {best_model_name} model on full data...\")\n",
        "        final_model_instance = clone(best_estimator)\n",
        "\n",
        "        if hasattr(final_model_instance, 'random_state'):\n",
        "            final_model_instance.random_state = 42\n",
        "\n",
        "        fit_params_full = {}\n",
        "        # Modify the condition, add handling for LGBMClassifier\n",
        "        if sample_weights is not None and isinstance(final_model_instance, (LogisticRegression, xgb.XGBClassifier, lgb.LGBMClassifier)):\n",
        "            fit_params_full['sample_weight'] = sample_weights\n",
        "\n",
        "        try:\n",
        "            final_model_instance.fit(X_target_full, y_target, **fit_params_full)\n",
        "        except Exception as e:\n",
        "            print(f\"Error training final model {best_model_name}: {e}\")\n",
        "            final_models[target] = {'model': None, 'features': features_for_target, 'threshold': optimal_threshold, 'auc': final_cv_mean_auc, 'model_name': best_model_name}\n",
        "            continue\n",
        "\n",
        "        # Store results\n",
        "        final_models[target] = {'model': final_model_instance, 'features': features_for_target, 'threshold': optimal_threshold, 'auc': final_cv_mean_auc, 'model_name': best_model_name}\n",
        "        print(f\"  Stored final model for {target}.\")\n",
        "\n",
        "    print(\"\\nFinished training and tuning.\")\n",
        "    # Return value includes OOF\n",
        "    return tuning_results, final_models, oof_predictions\n",
        "\n",
        "# ====================================\n",
        "# 11. Feature Importance Visualization\n",
        "# ====================================\n",
        "def plot_feature_importance(model, features, target, top_n=20):\n",
        "    \"\"\"Plots a feature importance chart\"\"\"\n",
        "    # [Function body same as before]\n",
        "    if model is None: print(f\"Cannot plot importance for {target}, model is None.\"); return\n",
        "    if not hasattr(model, 'feature_importances_'): print(f\"Warning: Model {model.__class__.__name__} for {target} does not support feature importance.\"); return\n",
        "    try:\n",
        "        importances = model.feature_importances_\n",
        "        if not features or len(features) != len(importances):\n",
        "            print(f\"Warning: Feature list length mismatch for {target} ({len(features)} vs {len(importances)}). Plot may be incorrect.\")\n",
        "            internal_names = None\n",
        "            if hasattr(model, 'feature_names_in_'): internal_names = model.feature_names_in_.tolist()\n",
        "            elif hasattr(model, 'feature_name_'): internal_names = model.feature_name_()\n",
        "            if internal_names and len(internal_names) == len(importances): print(\"  Using model's internal feature names.\"); features = internal_names\n",
        "            else: print(\"  Skipping plot.\"); return\n",
        "        indices = np.argsort(importances)[::-1]; plot_n = min(top_n, len(features)); indices = indices[:plot_n]\n",
        "        plt.figure(figsize=(10, max(6, plot_n * 0.3))); plt.title(f'{target} - Top {plot_n} Feature Importance ({model.__class__.__name__})')\n",
        "        plt.barh(range(len(indices)), importances[indices][::-1], align='center'); plt.yticks(range(len(indices)), np.array(features)[indices][::-1])\n",
        "        plt.xlabel('Relative Importance'); plt.tight_layout(); plt.savefig(f'{target}_feature_importance.png')\n",
        "    except Exception as e_plot: print(f\"Error plotting importance for {target}: {e_plot}\")\n",
        "    finally: plt.close()\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 12. Test Set Prediction\n",
        "# ====================================\n",
        "\n",
        "# --- Helper Function: Calibrate Threshold ---\n",
        "def calibrate_threshold(y_proba, target_ratio=0.685):\n",
        "    \"\"\" Calibrates threshold to match a target ratio (more robust version) \"\"\"\n",
        "    # [Function body same as before]\n",
        "    if not isinstance(y_proba, np.ndarray): y_proba = np.array(y_proba)\n",
        "    n_samples = len(y_proba)\n",
        "    if n_samples == 0: print(\"Warning (calibrate): Input is empty\"); return 0.5\n",
        "    if np.all(np.isclose(y_proba, y_proba[0])): return y_proba[0]\n",
        "    n_positives_target = int(round(n_samples * target_ratio))\n",
        "    if n_positives_target <= 0: return np.max(y_proba) + 1e-7\n",
        "    if n_positives_target >= n_samples: return np.min(y_proba) - 1e-7\n",
        "    sorted_probs = np.sort(y_proba)[::-1]\n",
        "    threshold_lower = sorted_probs[n_positives_target]\n",
        "    if n_positives_target > 0:\n",
        "        threshold_upper = sorted_probs[n_positives_target - 1]\n",
        "        if np.isclose(threshold_upper, threshold_lower): calibrated_threshold = threshold_lower - 1e-7\n",
        "        else: calibrated_threshold = (threshold_upper + threshold_lower) / 2.0\n",
        "    else: calibrated_threshold = threshold_lower + 1e-7\n",
        "    return np.clip(calibrated_threshold, 0.0, 1.0)\n",
        "\n",
        "# --- Main Prediction Function ---\n",
        "def make_predictions(X_test, final_models, test_multimodal):\n",
        "    \"\"\"Makes predictions on the test set using the trained models. Sorts features as expected by the model.\"\"\"\n",
        "    # [Function body same as before]\n",
        "    print(\"\\nGenerating test set predictions...\")\n",
        "    if X_test is None or not isinstance(X_test, pd.DataFrame):\n",
        "        print(\"Error: Valid test data needed.\");\n",
        "        if test_multimodal is not None and 'participant_id' in test_multimodal.columns:\n",
        "            submission = pd.DataFrame({'participant_id': test_multimodal['participant_id']}); expected_targets = list(final_models.keys()) if final_models else ['ADHD_Outcome', 'Sex_F']\n",
        "            for target in expected_targets: submission[target] = 0; print(\"Returning default 0 submission.\"); return submission, {}\n",
        "        else: print(\"Cannot create submission.\"); return None, None\n",
        "    if test_multimodal is None or 'participant_id' not in test_multimodal.columns: print(\"Error: test_multimodal required.\"); return None, None\n",
        "    predictions = {}\n",
        "    for target, model_info in final_models.items():\n",
        "        print(f\"\\n--- Predicting for Target: {target} ---\")\n",
        "        model = model_info.get('model'); features_subset_list = model_info.get('features'); model_name = model_info.get('model_name', 'N/A')\n",
        "        if model is None or features_subset_list is None or not features_subset_list: print(f\"Warning: Invalid model/features for {target}. Skipping.\"); predictions[target] = {'probability': np.zeros(len(X_test)), 'prediction': np.zeros(len(X_test), dtype=int)}; continue\n",
        "        features_expected_by_model = [];\n",
        "        try:\n",
        "            if hasattr(model, 'feature_name_'): features_expected_by_model = model.feature_name_()\n",
        "            elif hasattr(model, 'feature_names_in_'): features_expected_by_model = model.feature_names_in_.tolist()\n",
        "            else: print(f\"Warning: Cannot get expected features for {target}. Using stored list.\"); features_expected_by_model = features_subset_list\n",
        "            if not features_expected_by_model: print(f\"Error: Model {target} has no expected features.\"); features_expected_by_model = features_subset_list\n",
        "        except Exception as debug_e: print(f\"Warning: Error getting expected features: {debug_e}.\"); features_expected_by_model = features_subset_list\n",
        "        missing_features = [f for f in features_expected_by_model if f not in X_test.columns]\n",
        "        if missing_features: print(f\"Error: Features missing in X_test: {missing_features}. Skipping.\"); predictions[target] = {'probability': np.zeros(len(X_test)), 'prediction': np.zeros(len(X_test), dtype=int)}; continue\n",
        "        try: X_test_features = X_test[features_expected_by_model]; print(f\"  Prepared test data {X_test_features.shape} in model order.\")\n",
        "        except Exception as e_reorder: print(f\"Error selecting/reordering cols: {e_reorder}. Skipping.\"); predictions[target] = {'probability': np.zeros(len(X_test)), 'prediction': np.zeros(len(X_test), dtype=int)}; continue\n",
        "        try:\n",
        "            y_pred_proba = model.predict_proba(X_test_features)[:, 1]; final_threshold = 0.5\n",
        "            if target == 'ADHD_Outcome':\n",
        "                try: final_threshold = calibrate_threshold(y_pred_proba, target_ratio=0.685); print(f\"  Using calibrated threshold: {final_threshold:.4f}\")\n",
        "                except Exception as cal_e: print(f\"  Warning: Calibration error: {cal_e}. Using 0.5.\")\n",
        "            else: final_threshold = model_info.get('threshold', 0.5); print(f\"  Using optimal threshold: {final_threshold:.4f}\")\n",
        "            y_pred = (y_pred_proba >= final_threshold).astype(int); predictions[target] = { 'probability': y_pred_proba, 'prediction': y_pred }\n",
        "            print(f\"  Prediction successful. Positive ratio: {np.mean(y_pred):.2f}\")\n",
        "        except Exception as e: print(f\"Error during predict_proba for {target}: {e}\"); print(f\"    Data shape: {X_test_features.shape}\"); predictions[target] = {'probability': np.zeros(len(X_test)), 'prediction': np.zeros(len(X_test), dtype=int)}\n",
        "    print(\"\\nCreating submission file...\")\n",
        "    submission = pd.DataFrame({'participant_id': test_multimodal['participant_id']})\n",
        "    expected_targets = list(final_models.keys()) if final_models else ['ADHD_Outcome', 'Sex_F']\n",
        "    for target in expected_targets:\n",
        "        pred_val = predictions.get(target, {}).get('prediction', np.zeros(len(submission), dtype=int))\n",
        "        if len(pred_val) != len(submission): print(f\"Warning: Prediction length mismatch for target {target}!\"); submission[target] = 0\n",
        "        else: submission[target] = pred_val\n",
        "    return submission, predictions\n",
        "\n",
        "\n",
        "\n",
        "# ====================================\n",
        "def main():\n",
        "    \"\"\"Runs the complete WiDS Datathon 2025 ADHD and Gender Prediction pipeline (two-stage prediction version)\"\"\"\n",
        "    print(\"WiDS Datathon 2025 - ADHD and Gender Prediction Model using Multimodal Data (Two-Stage Prediction Version)\")\n",
        "    print(\"======================================================================\")\n",
        "\n",
        "    # --- [File Path Setup and Check] ---\n",
        "    drive_dir = '/content/drive/MyDrive/wids_datathon'\n",
        "    if IN_COLAB and not os.path.exists(drive_dir): print(\"Mounting Google Drive...\"); drive.mount('/content/drive')\n",
        "    elif not IN_COLAB and not os.path.exists(drive_dir): print(f\"Error: Drive directory does not exist: {drive_dir}\"); return None\n",
        "    train_cat_path = os.path.join(drive_dir, \"TRAIN_CATEGORICAL_METADATA_new.xlsx\"); train_quant_path = os.path.join(drive_dir, \"TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
        "    solutions_path = os.path.join(drive_dir, \"TRAINING_SOLUTIONS.xlsx\"); test_cat_path = os.path.join(drive_dir, \"TEST_CATEGORICAL.xlsx\")\n",
        "    test_quant_path = os.path.join(drive_dir, \"TEST_QUANTITATIVE_METADATA.xlsx\"); train_connectome_path = os.path.join(drive_dir, \"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
        "    test_connectome_path = os.path.join(drive_dir, \"TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
        "    file_paths = [train_cat_path, train_quant_path, solutions_path, test_cat_path, test_quant_path, train_connectome_path, test_connectome_path]\n",
        "    if not all(os.path.exists(path) for path in file_paths): print(\"Error: Some files do not exist.\"); missing = [p for p in file_paths if not os.path.exists(p)]; print(f\"Missing: {missing}\"); return None\n",
        "    print(\"All files found in Google Drive. Starting analysis...\")\n",
        "\n",
        "    # --- 1. Load Data ---\n",
        "    train_cat, train_quant, train_con, solutions, test_cat, test_quant, test_con = load_data(train_cat_path, train_quant_path, solutions_path, test_cat_path, test_quant_path, train_connectome_path, test_connectome_path)\n",
        "    if train_cat is None or train_quant is None or solutions is None: print(\"Error: Core training data failed to load.\"); return None\n",
        "\n",
        "    # --- 2. Merge ---\n",
        "    train_merged, test_merged = preprocess_and_merge_data(train_cat, train_quant, solutions, test_cat, test_quant)\n",
        "    if train_merged is None: print(\"Error: Training data merge failed.\"); return None\n",
        "\n",
        "    # --- 3. Connectome Features (with Harmonization) ---\n",
        "    print(\"\\n--- Preparing Data for Harmonization (if applicable) ---\")\n",
        "    # Use raw data by default\n",
        "    train_con_to_process = train_con\n",
        "    test_con_to_process = test_con\n",
        "    apply_harmonization = True # Or set to False to skip\n",
        "\n",
        "    if apply_harmonization and train_con is not None and train_cat is not None:\n",
        "        try:\n",
        "            from neuroHarmonize import harmonizationLearn\n",
        "            print(\"  Applying Harmonization data harmonization...\")\n",
        "            # --- Harmonization Logic ---\n",
        "            batch_col = 'MRI_Track_Scan_Location' # Select batch variable\n",
        "            if batch_col not in train_cat.columns or (test_cat is not None and batch_col not in test_cat.columns):\n",
        "                print(f\"Warning: Cannot find batch variable '{batch_col}' in categorical data, skipping Harmonization.\")\n",
        "            else:\n",
        "                # Prepare covariates\n",
        "                train_covars = train_cat[['participant_id', batch_col]].copy()\n",
        "                test_covars = test_cat[['participant_id', batch_col]].copy() if test_cat is not None else pd.DataFrame(columns=['participant_id', batch_col])\n",
        "                all_covars = pd.concat([train_covars, test_covars], ignore_index=True).drop_duplicates(subset=['participant_id']).set_index('participant_id')\n",
        "\n",
        "                # Merge connectome data\n",
        "                all_conn = train_con.copy().set_index('participant_id')\n",
        "                if test_con is not None:\n",
        "                    all_conn = pd.concat([all_conn, test_con.copy().set_index('participant_id')], axis=0)\n",
        "\n",
        "                # Align indices\n",
        "                common_ids = all_covars.index.intersection(all_conn.index)\n",
        "                print(f\"  Found {len(common_ids)} common participants for Harmonization.\")\n",
        "                all_covars = all_covars.loc[common_ids]\n",
        "                all_conn_aligned = all_conn.loc[common_ids]\n",
        "                connectome_features = all_conn_aligned.columns.tolist() # Get feature column names\n",
        "\n",
        "                # Handle missing covariate values\n",
        "                if all_covars[batch_col].isnull().any():\n",
        "                    mode_site = all_covars[batch_col].mode()[0]\n",
        "                    print(f\"  Filling missing values in '{batch_col}' with mode: {mode_site}\")\n",
        "                    all_covars[batch_col].fillna(mode_site, inplace=True)\n",
        "                all_covars[batch_col] = all_covars[batch_col].astype(str)\n",
        "\n",
        "                # Execute Harmonization\n",
        "                print(f\"  Executing Harmonization using '{batch_col}' as the batch variable...\")\n",
        "                connectome_data_array = all_conn_aligned.values\n",
        "                covars_df = all_covars[[batch_col]] # Only pass the batch variable\n",
        "                # --- Fix: Ensure column names meet neuroHarmonize requirements (e.g., 'SITE') ---\n",
        "                covars_df.rename(columns={batch_col: 'SITE'}, inplace=True) # <--- Add renaming\n",
        "\n",
        "                harm_model, data_harmonized = harmonizationLearn(connectome_data_array, covars_df, eb=True)\n",
        "                print(f\"  Harmonization complete.\")\n",
        "\n",
        "                # Convert back to DataFrame and separate\n",
        "                harmonized_df = pd.DataFrame(data_harmonized, index=common_ids, columns=connectome_features)\n",
        "                harmonized_df.reset_index(inplace=True) # participant_id becomes a column again\n",
        "                train_ids = train_con['participant_id'].unique().tolist()\n",
        "                train_con_harmonized = harmonized_df[harmonized_df['participant_id'].isin(train_ids)]\n",
        "                if test_con is not None:\n",
        "                    test_ids = test_con['participant_id'].unique().tolist()\n",
        "                    test_con_harmonized = harmonized_df[harmonized_df['participant_id'].isin(test_ids)]\n",
        "                else:\n",
        "                    test_con_harmonized = None\n",
        "\n",
        "                # --- Replace original variables with harmonized data ---\n",
        "                train_con_to_process = train_con_harmonized\n",
        "                test_con_to_process = test_con_harmonized\n",
        "\n",
        "        except ImportError: print(\"Warning: neuroHarmonize not installed, skipping Harmonization\")\n",
        "        except Exception as e_harm: print(f\"Warning: Harmonization failed: {e_harm}. Continuing with raw data...\")\n",
        "    else:\n",
        "        if apply_harmonization: print(\"\\nInfo: Harmonization not performed (due to missing necessary data or apply_harmonization=False).\")\n",
        "\n",
        "    # --- Call process_connectome_data (using raw or harmonized data) ---\n",
        "    # ===> Corrected call: only pass connectome data <===\n",
        "    train_connectome_features, test_connectome_features = process_connectome_data(\n",
        "        train_con_to_process,\n",
        "        test_con_to_process\n",
        "    )\n",
        "    if train_connectome_features is None: print(\"Warning: Failed to extract training connectome features.\")\n",
        "\n",
        "    # --- 4. Multimodal Fusion ---\n",
        "    train_multimodal, test_multimodal = multimodal_fusion(train_merged, train_connectome_features, test_merged, test_connectome_features)\n",
        "    if train_multimodal is None: print(\"Error: Training data fusion failed.\"); return None\n",
        "    if test_multimodal is None and test_merged is not None: test_multimodal = test_merged[['participant_id']].copy()\n",
        "    if test_multimodal is None: print(\"Error: Could not get test IDs\"); return None\n",
        "\n",
        "\n",
        "    # --- 5. Initial Feature Engineering (Restored version - no extra interaction features) ---\n",
        "    # Consider removing the location feature here (if Harmonization was successful)\n",
        "    batch_col = 'MRI_Track_Scan_Location' # Assume this is the column used for Harmonization\n",
        "    if 'harm_model' in locals() or apply_harmonization: # If harmonization was attempted\n",
        "        if batch_col in train_multimodal.columns: train_multimodal = train_multimodal.drop(columns=[batch_col], errors='ignore')\n",
        "        if test_multimodal is not None and batch_col in test_multimodal.columns: test_multimodal = test_multimodal.drop(columns=[batch_col], errors='ignore')\n",
        "        print(f\"Info: Removed location feature '{batch_col}' (assuming it was handled by Harmonization).\")\n",
        "\n",
        "    X_train_base, y_train, X_test_base, preprocessor, feature_names = feature_engineering(train_multimodal, test_multimodal)\n",
        "    if X_train_base is None or y_train is None: print(\"Error: Feature engineering failed.\"); return None\n",
        "\n",
        "    # --- 6. Initial Feature Selection ---\n",
        "    print(\"\\n--- Initial Feature Selection (using base features) ---\")\n",
        "    _, selected_features_dict = select_features(X_train_base, y_train, n_features=30)\n",
        "    if not selected_features_dict: print(\"Warning: Initial feature selection failed.\"); selected_features_dict = {t: X_train_base.columns.tolist() for t in y_train.columns}\n",
        "\n",
        "    # --- 7. Calculate Sample Weights ---\n",
        "    sample_weights = calculate_optimized_weights(y_train, female_adhd_boost=2.0, female_non_adhd_boost=1.2, male_non_adhd_boost=1.5, male_adhd_boost=1.5)\n",
        "    if sample_weights is None: print(\"Warning: Sample weight calculation failed.\")\n",
        "\n",
        "    # --- 8. Stage 1: Train Sex_F Model and Get Predictions ---\n",
        "    print(\"\\n===== Stage 1: Training Sex_F Model =====\")\n",
        "    sex_features_list = selected_features_dict.get('Sex_F', X_train_base.columns.tolist())\n",
        "    sex_feature_dict_for_train = {'Sex_F': sex_features_list}\n",
        "    tuning_results_sex, final_models_sex, oof_predictions_sex = train_models_with_cv(\n",
        "        X_train_base, y_train[['Sex_F']], sex_feature_dict_for_train,\n",
        "        target_to_process=['Sex_F'], sample_weights=sample_weights,\n",
        "        n_splits=5, n_repeats=5, n_tuning_iter=50, inner_cv_folds=5\n",
        "    )\n",
        "    if 'Sex_F' not in final_models_sex or final_models_sex['Sex_F']['model'] is None: print(\"Error: Sex model training failed.\"); return None\n",
        "    oof_sex_proba = oof_predictions_sex.get('Sex_F');\n",
        "    if oof_sex_proba is None: print(\"Error: Failed to get OOF sex predictions.\"); return None\n",
        "    test_sex_proba = None\n",
        "    if X_test_base is not None:\n",
        "        final_sex_model = final_models_sex['Sex_F']['model']; sex_model_features = final_models_sex['Sex_F']['features']\n",
        "        features_expected_sex = [];\n",
        "        try: # Get expected feature order from the model\n",
        "            if hasattr(final_sex_model, 'feature_names_in_'): features_expected_sex = final_sex_model.feature_names_in_.tolist()\n",
        "            else: features_expected_sex = sex_model_features\n",
        "            if not features_expected_sex: features_expected_sex = sex_model_features\n",
        "        except: features_expected_sex = sex_model_features\n",
        "        missing_test_sex_feats = [f for f in features_expected_sex if f not in X_test_base.columns]\n",
        "        if not missing_test_sex_feats:\n",
        "            try: test_sex_proba = final_sex_model.predict_proba(X_test_base[features_expected_sex])[:, 1]; print(\"  Successfully predicted Sex_F probabilities for the test set.\")\n",
        "            except Exception as e_pred_sex: print(f\"  Error predicting Sex_F probabilities for test set: {e_pred_sex}\")\n",
        "        else: print(f\"  Test set is missing features required by the Sex model: {missing_test_sex_feats}\")\n",
        "    if test_sex_proba is None: print(\"Warning: Failed to generate Sex_F prediction probabilities for the test set.\")\n",
        "\n",
        "    # --- 9. Augment Feature Set (add sex_proba and interaction terms - revised version) ---\n",
        "    print(\"\\n--- Augmenting Features with Sex Predictions ---\")\n",
        "    X_train_aug = X_train_base.copy(); X_train_aug['sex_proba_oof'] = oof_sex_proba\n",
        "    X_test_aug = None\n",
        "    if X_test_base is not None:\n",
        "        X_test_aug = X_test_base.copy()\n",
        "        if test_sex_proba is not None: X_test_aug['sex_proba_pred'] = test_sex_proba\n",
        "        else: X_test_aug['sex_proba_pred'] = np.mean(oof_sex_proba); print(\"  Warning: Filling test set's sex_proba_pred with the training set's average probability\")\n",
        "\n",
        "    # --- Use the correct prefixed feature names ---\n",
        "    base_feature_map = {\n",
        "        'MRI_Track_Age_at_Scan': [c for c in X_train_base.columns if 'MRI_Track_Age_at_Scan' in c],\n",
        "        'SDQ_SDQ_Hyperactivity': [c for c in X_train_base.columns if 'SDQ_SDQ_Hyperactivity' in c],\n",
        "        'skewness': [c for c in X_train_base.columns if 'skewness' in c],\n",
        "        'min_degree': [c for c in X_train_base.columns if 'min_degree' in c]\n",
        "    }\n",
        "    interaction_base_features_prefixed = []\n",
        "    for base_name, found_names in base_feature_map.items():\n",
        "        if found_names: interaction_base_features_prefixed.append(found_names[0])\n",
        "        else: print(f\"Warning: Could not find base feature '{base_name}' for interaction.\")\n",
        "    print(f\"  The following features will be used to create interaction terms with sex probability: {interaction_base_features_prefixed}\")\n",
        "\n",
        "    # --- Create Interaction Features ---\n",
        "    added_train_interactions = []; added_test_interactions = []\n",
        "    for feat_prefixed in interaction_base_features_prefixed:\n",
        "        interaction_name = f\"{feat_prefixed}_x_sexproba\"\n",
        "        X_train_aug[interaction_name] = X_train_aug[feat_prefixed] * X_train_aug['sex_proba_oof']; added_train_interactions.append(interaction_name)\n",
        "        if X_test_aug is not None and feat_prefixed in X_test_aug.columns and 'sex_proba_pred' in X_test_aug.columns:\n",
        "            X_test_aug[interaction_name] = X_test_aug[feat_prefixed] * X_test_aug['sex_proba_pred']; added_test_interactions.append(interaction_name)\n",
        "    print(f\"  Added {len(added_train_interactions)} interaction features to the training set.\")\n",
        "    if X_test_aug is not None: print(f\"  Added {len(added_test_interactions)} interaction features to the test set.\")\n",
        "\n",
        "    # --- Column Alignment ---\n",
        "    if X_test_aug is not None:\n",
        "        expected_aug_cols = X_train_aug.columns.tolist()\n",
        "        rename_map = {'sex_proba_pred': 'sex_proba_oof'}\n",
        "        rename_map.update({f\"{f}_x_sexproba\": f\"{f}_x_sexproba\" for f in interaction_base_features_prefixed}) # Use prefixed base names\n",
        "        X_test_aug_renamed = X_test_aug.rename(columns=rename_map)\n",
        "        final_test_cols = [col for col in expected_aug_cols if col in X_test_aug_renamed.columns]\n",
        "        missing_final = list(set(expected_aug_cols) - set(final_test_cols))\n",
        "        if missing_final: print(f\"Warning: Test set is still missing columns after final alignment: {missing_final}\")\n",
        "        X_test_aug = X_test_aug_renamed[final_test_cols]\n",
        "        if X_test_aug.empty and not X_test_base.empty : print(\"Warning: Test set became empty after alignment!\") # Added check\n",
        "\n",
        "    # --- 10. Feature Selection Again (only for ADHD, using augmented feature set) ---\n",
        "    print(\"\\n--- Feature Selection for ADHD (using augmented features) ---\")\n",
        "    _, selected_features_dict_adhd = select_features(X_train_aug, y_train[['ADHD_Outcome']], n_features=20)\n",
        "    if not selected_features_dict_adhd: print(\"Warning: ADHD feature selection failed.\"); selected_features_dict_adhd = {'ADHD_Outcome': X_train_aug.columns.tolist()}\n",
        "\n",
        "    # --- 11. Stage 2: Train ADHD Model ---\n",
        "    print(\"\\n===== Stage 2: Training ADHD_Outcome Model =====\")\n",
        "    adhd_feature_dict_for_train = {'ADHD_Outcome': selected_features_dict_adhd.get('ADHD_Outcome', X_train_aug.columns.tolist())}\n",
        "    tuning_results_adhd, final_models_adhd, oof_predictions_adhd = train_models_with_cv(\n",
        "        X_train_aug, y_train[['ADHD_Outcome']], adhd_feature_dict_for_train,\n",
        "        target_to_process=['ADHD_Outcome'], sample_weights=sample_weights,\n",
        "        n_splits=5, n_repeats=5, n_tuning_iter=50, inner_cv_folds=5 # <--- Increased CV and tuning intensity\n",
        "    )\n",
        "    if 'ADHD_Outcome' not in final_models_adhd or final_models_adhd['ADHD_Outcome']['model'] is None: print(\"Error: ADHD model training failed.\"); return None\n",
        "\n",
        "    # --- 12. Generate Final Predictions ---\n",
        "    print(\"\\n--- Generating Final Predictions (Two-Stage) ---\")\n",
        "    final_predictions = {}\n",
        "    # Sex_F prediction\n",
        "    if test_sex_proba is not None: sex_threshold = final_models_sex['Sex_F'].get('threshold', 0.5); final_predictions['Sex_F'] = (test_sex_proba >= sex_threshold).astype(int); print(f\"Sex_F prediction generated (Thr: {sex_threshold:.4f}). Ratio: {np.mean(final_predictions['Sex_F']):.2f}\")\n",
        "    else: final_predictions['Sex_F'] = np.zeros(len(test_multimodal), dtype=int); print(\"Warning: Sex_F prediction used defaults.\")\n",
        "    # ADHD prediction\n",
        "    if X_test_aug is not None:\n",
        "        final_adhd_model = final_models_adhd['ADHD_Outcome']['model']; adhd_model_features = final_models_adhd['ADHD_Outcome']['features']\n",
        "        features_expected_adhd = [];\n",
        "        try: # Get expected feature order from the model\n",
        "            if hasattr(final_adhd_model, 'feature_names_in_'): features_expected_adhd = final_adhd_model.feature_names_in_.tolist()\n",
        "            else: features_expected_adhd = adhd_model_features\n",
        "        except: features_expected_adhd = adhd_model_features\n",
        "        missing_test_adhd_feats = [f for f in features_expected_adhd if f not in X_test_aug.columns]\n",
        "        if not missing_test_adhd_feats:\n",
        "            try:\n",
        "                test_adhd_proba = final_adhd_model.predict_proba(X_test_aug[features_expected_adhd])[:, 1]\n",
        "                adhd_threshold = calibrate_threshold(test_adhd_proba, target_ratio=0.685)\n",
        "                final_predictions['ADHD_Outcome'] = (test_adhd_proba >= adhd_threshold).astype(int)\n",
        "                print(f\"ADHD prediction generated (Thr: {adhd_threshold:.4f}). Ratio: {np.mean(final_predictions['ADHD_Outcome']):.2f}\")\n",
        "            except Exception as e_pred_adhd: print(f\"  Error predicting ADHD: {e_pred_adhd}\")\n",
        "        else: print(f\"  Error: Test set missing features for ADHD: {missing_test_adhd_feats}\")\n",
        "    if 'ADHD_Outcome' not in final_predictions: print(\"Warning: ADHD prediction used defaults.\"); final_predictions['ADHD_Outcome'] = np.zeros(len(test_multimodal), dtype=int)\n",
        "\n",
        "    # --- 13. Create and Save Submission File ---\n",
        "    print(\"\\nCreating final submission file (Two-Stage)...\")\n",
        "    submission = pd.DataFrame({'participant_id': test_multimodal['participant_id']})\n",
        "    submission['ADHD_Outcome'] = final_predictions.get('ADHD_Outcome', 0) # Using .get() is safer\n",
        "    submission['Sex_F'] = final_predictions.get('Sex_F', 0)\n",
        "    submission_path = os.path.join(drive_dir, \"wids_datathon_submission_two_stage_final.csv\") # Update filename\n",
        "    try: submission.to_csv(submission_path, index=False); print(f\"\\nSubmission file saved: {submission_path}\"); print(\"\\nSubmission file preview:\"); print(submission.head())\n",
        "    except Exception as e_save: print(f\"\\nError: Failed to save submission file: {e_save}\")\n",
        "\n",
        "    # --- 14. Visualization and Saving Charts ---\n",
        "    print(\"\\nGenerating feature importance plots...\")\n",
        "    charts_dir = os.path.join(drive_dir, \"charts\")\n",
        "\n",
        "    # Create charts directory (if it doesn't exist)\n",
        "    if not os.path.exists(charts_dir):\n",
        "        os.makedirs(charts_dir)\n",
        "        print(f\"Created charts directory: {charts_dir}\")\n",
        "\n",
        "    # Merge dictionaries for convenient looping\n",
        "    final_models_for_plot = {**final_models_sex, **final_models_adhd}\n",
        "\n",
        "    # Plot feature importance charts\n",
        "    for target, model_info in final_models_for_plot.items():\n",
        "        model = model_info.get('model')\n",
        "        features_list_for_model = model_info.get('features')\n",
        "\n",
        "        if model is not None and features_list_for_model:\n",
        "            print(f\"  Generating plot for {target} (Model: {model_info.get('model_name', '?')})...\")\n",
        "            plot_feature_importance(model, features_list_for_model, f\"{target}_final\", top_n=20)\n",
        "\n",
        "    # Copy charts to Google Drive\n",
        "    if charts_dir:\n",
        "        print(f\"\\nCopying charts to Google Drive ({charts_dir})...\")\n",
        "        for target in final_models_for_plot.keys():\n",
        "            try:\n",
        "                plot_file = f\"{target}_final_feature_importance.png\"\n",
        "                if os.path.exists(plot_file):\n",
        "                    dest_path = os.path.join(charts_dir, plot_file)\n",
        "                    shutil.copy(plot_file, dest_path)\n",
        "                    print(f\"  Copied {plot_file} to charts directory\")\n",
        "                else:\n",
        "                    print(f\"  Warning: {plot_file} not found\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error copying {plot_file}: {e}\")\n",
        "\n",
        "    # --- 15. Download Option ---\n",
        "    if IN_COLAB:\n",
        "        try:\n",
        "            if 'submission_path' in locals() and os.path.exists(submission_path): print(\"\\nDownload submission file? (y/n):\"); download_response = input();\n",
        "            if download_response.lower() == 'y': files.download(submission_path)\n",
        "        except Exception as e_download: print(f\"Download prompt error: {e_download}\")\n",
        "    else: print(\"\\nNot in Colab. Skipping download prompt.\")\n",
        "\n",
        "    # --- 16. Return Results ---\n",
        "    print(\"\\nPipeline finished (Two-Stage).\")\n",
        "    return {'final_models': {**final_models_sex, **final_models_adhd}, 'submission': submission}\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# Script Execution Entry Point\n",
        "# ====================================\n",
        "if __name__ == \"__main__\":\n",
        "    result_objects = main()"
      ],
      "metadata": {
        "id": "j_rZVylGAD4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}